{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Uses `Distribution`, `run_de`, and `fitness` in the file\n",
    "from method import *\n",
    "\n",
    "# Clean up the output\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 20241225"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real data experiments in the paper\n",
    "This file illustrates how to replicate the real data experiments, which is very similar to the instruction given in `Readme.md`\n",
    "\n",
    "Assume that the CGM data from Shah et al. (2019) and Brown et al. (2019) are accessed and processed as guided in the [Awesome-CGM](https://github.com/IrinaStatsLab/Awesome-CGM) repository, saved in `./data/shah2019_filtered.csv` and `./data/brown2019_filtered.csv`. \n",
    "\n",
    "These datasets are measured by Dexcom G6, having glucose ranges from 39 mg/dL to 401 mg/dL. This range should be specified as `ran=(39, 401)` when creating a `Distribution` class in a data-dependent manner.\n",
    "\n",
    "As the differential evolution (DE) is a stochastic algorithm, we fix `SEED=20241225` to reproduce the experimental results illustrated in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_shah = pd.read_csv(\"./data/shah2019_filtered.csv\")\n",
    "grouped_data = data_shah.groupby('id').agg({'gl': list}).reset_index()\n",
    "data_class_shah = Distribution(grouped_data[\"gl\"], ran=(39., 401.), M=200)\n",
    "\n",
    "# data_brown = pd.read_csv(\"./data/brown2019_filtered.csv\")\n",
    "data_brown = pd.read_csv(\"./data/o_malley2021_filtered.csv\")\n",
    "grouped_data = data_brown.groupby('id').agg({'gl': list}).reset_index()\n",
    "data_class_brown = Distribution(grouped_data[\"gl\"], ran=(39., 401.), M=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making data into `Distribution` classes, we can run `run_de` with specified target number of thresholds `K` and the threshold-optimality criteria: `loss=\"Loss1\"` or `loss=\"Loss2\"`. \n",
    "\n",
    "Below are example usages with $K=4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shah dataset with K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 39.    75.83 100.69 123.7  154.96 401.  ]\n",
      "Obtained loss: 16.619439163631053\n"
     ]
    }
   ],
   "source": [
    "# L_1 loss\n",
    "best_cutoffs, min_loss = run_de(data_class_shah, K=4, loss=\"Loss1\", seed=SEED)\n",
    "print(best_cutoffs)\n",
    "print(\"Obtained loss:\", min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 39.   168.89 249.13 294.49 351.83 401.  ]\n",
      "Obtained loss (x 10^{-3}): 30.808015190380164\n"
     ]
    }
   ],
   "source": [
    "# L_2 loss (takes about 4 minutes)\n",
    "best_cutoffs2, min_loss2 = run_de(data_class_shah, K=4, loss=\"Loss2\", seed=SEED)\n",
    "print(best_cutoffs2)\n",
    "print(\"Obtained loss (x 10^{-3}):\", min_loss2 / 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Brown dataset with K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 39.    84.88 171.2  232.62 301.58 401.  ]\n",
      "Obtained loss: 40.657398455283754\n"
     ]
    }
   ],
   "source": [
    "# L_1 loss\n",
    "best_cutoffs, min_loss = run_de(data_class_brown, K=4, loss=\"Loss1\", seed=SEED)\n",
    "print(best_cutoffs)\n",
    "print(\"Obtained loss:\", min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 39.   168.89 249.13 294.49 351.83 401.  ]\n",
      "Obtained loss (x 10^{-3}): 30.808015190380164\n"
     ]
    }
   ],
   "source": [
    "# L_2 loss (takes about 5 minutes)\n",
    "best_cutoffs2, min_loss2 = run_de(data_class_brown, K=4, loss=\"Loss2\", seed=SEED)\n",
    "print(best_cutoffs2)\n",
    "print(\"Obtained loss (x 10^{-3}):\", min_loss2 / 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimality measures at the traditional thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shah dataset\n",
      "    L1 at two traditional: 656.8785795451477\n",
      "    L1 at four traditional: 655.939314472095\n",
      "    L2 at two traditional: 28.32808440253849 (multiplied by 10^{-3})\n",
      "    L2 at four traditional: 28.801864648312193 (multiplied by 10^{-3})\n",
      "\n",
      "Brown dataset\n",
      "    L1 at two traditional: 1235.9789988634705\n",
      "    L1 at four traditional: 159.90153344550367\n",
      "    L2 at two traditional: 1450.9149694569626 (multiplied by 10^{-3})\n",
      "    L2 at four traditional: 92.74154648603994 (multiplied by 10^{-3})\n"
     ]
    }
   ],
   "source": [
    "print(\"Shah dataset\")\n",
    "print(\"    L1 at two traditional:\", fitness([70, 181], data_class_shah, loss=\"Loss1\"))\n",
    "print(\"    L1 at four traditional:\", fitness([54, 70, 181, 251], data_class_shah, loss=\"Loss1\"))\n",
    "\n",
    "# Precompute the Wasserstein distance matrix for L2 loss calculation\n",
    "data_class_shah.Wdist_matrix()\n",
    "print(\"    L2 at two traditional:\", fitness([70, 181], data_class_shah, loss=\"Loss2\") / 1000, \"(multiplied by 10^{-3})\")\n",
    "print(\"    L2 at four traditional:\", fitness([54, 70, 181, 251], data_class_shah, loss=\"Loss2\") / 1000, \"(multiplied by 10^{-3})\")\n",
    "\n",
    "print(\"\\nBrown dataset\")\n",
    "print(\"    L1 at two traditional:\", fitness([70, 181], data_class_brown, loss=\"Loss1\"))\n",
    "print(\"    L1 at four traditional:\", fitness([54, 70, 181, 251], data_class_brown, loss=\"Loss1\"))\n",
    "\n",
    "# Precompute the Wasserstein distance matrix for L2 loss calculation\n",
    "data_class_brown.Wdist_matrix()\n",
    "print(\"    L2 at two traditional:\", fitness([70, 181], data_class_brown, loss=\"Loss2\") / 1000, \"(multiplied by 10^{-3})\")\n",
    "print(\"    L2 at four traditional:\", fitness([54, 70, 181, 251], data_class_brown, loss=\"Loss2\") / 1000, \"(multiplied by 10^{-3})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
